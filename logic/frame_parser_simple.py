import torch
import supervision as sv
import numpy as np
import math
import time
from collections import deque, defaultdict

from logic.hotkeys_watcher import hotkeys_watcher
from logic.config_watcher import cfg
from logic.capture import capture
from logic.visual import visuals
from logic.mouse_simple import mouse
from logic.shooting import shooting
from logic.logger import logger

class SimpleTarget:
    """ç®€åŒ–çš„ç›®æ ‡ç±» - åªä¿ç•™å¿…è¦ä¿¡æ¯"""
    def __init__(self, x, y, w, h, cls, timestamp=None):
        self.x = x  # ä¸­å¿ƒXåæ ‡
        self.y = y  # ä¸­å¿ƒYåæ ‡
        self.w = w  # å®½åº¦
        self.h = h  # é«˜åº¦
        self.cls = cls  # ç±»åˆ« (7=å¤´éƒ¨)
        self.timestamp = timestamp or time.time()
        
        # è®¡ç®—ç²¾ç¡®ç„å‡†ç‚¹
        self.aim_x, self.aim_y = self.calculate_aim_point()
        
        # é¢„æµ‹ç›¸å…³å±æ€§
        self.predicted_x = x
        self.predicted_y = y
        self.velocity_x = 0.0
        self.velocity_y = 0.0
    
    def calculate_aim_point(self):
        """ç®€åŒ–çš„ç„å‡†ç‚¹è®¡ç®— - å‡å°‘å¤æ‚åº¦"""
        # ç®€åŒ–çš„ç„å‡†ç‚¹é€»è¾‘
        if self.cls == 7:  # å¤´éƒ¨ç›®æ ‡
            # å¤´éƒ¨ç›®æ ‡å›ºå®šåç§»ï¼šä¸­å¿ƒåä¸‹30%
            aim_x = self.x
            aim_y = self.y + (self.h * 0.3)
        else:  # èº«ä½“ç›®æ ‡
            # èº«ä½“ç›®æ ‡å›ºå®šåç§»ï¼šä¸­å¿ƒåä¸Š20%
            aim_x = self.x  
            aim_y = self.y - (self.h * 0.2)
        
        # å‡å°‘æ—¥å¿—è¾“å‡º
        return aim_x, aim_y

class TargetTracker:
    """ç®€åŒ–çš„ç›®æ ‡è·Ÿè¸ªå™¨ - ä¼˜å…ˆé€Ÿåº¦è€Œéç²¾åº¦"""
    
    def __init__(self, max_history=2):  # å‡å°‘å†å²è®°å½•
        self.target_history = defaultdict(lambda: deque(maxlen=max_history))
        self.prediction_enabled = not cfg.disable_prediction if hasattr(cfg, 'disable_prediction') else True
        
    def update_target(self, target):
        """ç®€åŒ–çš„ç›®æ ‡æ›´æ–°"""
        # ç®€åŒ–ç›®æ ‡keyï¼Œå‡å°‘è®¡ç®—
        target_key = f"{target.cls}_{int(target.x/100)}_{int(target.y/100)}"
        self.target_history[target_key].append({
            'x': target.x, 'y': target.y, 'timestamp': target.timestamp
        })
        return target_key
    
    def predict_position(self, target, prediction_time=0.03):  # å‡å°‘é¢„æµ‹æ—¶é—´
        """ç®€åŒ–çš„ä½ç½®é¢„æµ‹"""
        if not self.prediction_enabled:
            return target.x, target.y
            
        target_key = f"{target.cls}_{int(target.x/100)}_{int(target.y/100)}"
        history = self.target_history[target_key]
        
        if len(history) < 2:
            return target.x, target.y
        
        # åªä½¿ç”¨æœ€è¿‘çš„ä¸¤ä¸ªä½ç½®ï¼Œé¿å…å¤æ‚è®¡ç®—
        recent = history[-1]
        previous = history[-2]
        
        dt = recent['timestamp'] - previous['timestamp']
        if dt <= 0 or dt > 0.1:  # è¿‡å¤§çš„æ—¶é—´é—´éš”ä¸é¢„æµ‹
            return target.x, target.y
        
        velocity_x = (recent['x'] - previous['x']) / dt
        velocity_y = (recent['y'] - previous['y']) / dt
        
        # ç®€å•çš„é€Ÿåº¦é™åˆ¶ï¼ˆé¿å…è¿‡å¤§é¢„æµ‹ï¼‰
        max_velocity = 500  # åƒç´ /ç§’
        if abs(velocity_x) > max_velocity or abs(velocity_y) > max_velocity:
            return target.x, target.y
        
        # ç®€å•çš„çº¿æ€§é¢„æµ‹
        predicted_x = target.x + velocity_x * prediction_time
        predicted_y = target.y + velocity_y * prediction_time
        
        # å­˜å‚¨é€Ÿåº¦ä¿¡æ¯
        target.velocity_x = velocity_x
        target.velocity_y = velocity_y
        
        # ç®€åŒ–çš„è·ç¦»é™åˆ¶
        max_prediction_distance = 30  # å›ºå®šå€¼ï¼Œå‡å°‘è®¡ç®—
        prediction_distance = math.sqrt((predicted_x - target.x)**2 + (predicted_y - target.y)**2)
        
        if prediction_distance > max_prediction_distance:
            scale = max_prediction_distance / prediction_distance
            predicted_x = target.x + (predicted_x - target.x) * scale
            predicted_y = target.y + (predicted_y - target.y) * scale
        
        # å‡å°‘æ—¥å¿—è¾“å‡º
        if prediction_distance > 5:  # åªæœ‰åœ¨é¢„æµ‹è·ç¦»è¾ƒå¤§æ—¶æ‰æ‰“å°
            logger.info(f"ğŸ”® ç®€åŒ–é¢„æµ‹: ({target.x:.0f},{target.y:.0f}) -> ({predicted_x:.0f},{predicted_y:.0f})")
        
        return predicted_x, predicted_y

class SimpleFrameParser:
    """ç®€åŒ–çš„å¸§è§£æå™¨ - ä¸“æ³¨äºå¿«é€Ÿå‡†ç¡®çš„ç›®æ ‡å¤„ç† + é¢„æµ‹ç„å‡†"""
    
    def __init__(self):
        self.arch = self.get_arch()
        self.target_tracker = TargetTracker()
    
    def parse(self, result):
        """è§£ææ£€æµ‹ç»“æœå¹¶æ‰§è¡Œç„å‡†"""
        if isinstance(result, sv.Detections):
            self._process_sv_detections(result)
        else:
            self._process_yolo_detections(result)
    
    def _process_sv_detections(self, detections):
        """å¤„ç†supervisionæ ¼å¼çš„æ£€æµ‹ç»“æœ"""
        if detections.xyxy.any():
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            visuals.draw_helpers(detections)
            
            # æ‰¾åˆ°æœ€ä½³ç›®æ ‡
            target = self.find_best_target(detections)
            
            if target:
                self._execute_aim_and_shoot(target)
        else:
            # æ— ç›®æ ‡æ—¶æ¸…ç†æ˜¾ç¤º
            visuals.clear()
            # åœæ­¢å°„å‡»
            if cfg.auto_shoot or cfg.triggerbot:
                shooting.shoot(False, False)
    
    def _process_yolo_detections(self, results):
        """å¤„ç†YOLOæ ¼å¼çš„æ£€æµ‹ç»“æœ"""
        for frame in results:
            if frame.boxes:
                target = self.find_best_target(frame)
                if target:
                    self._execute_aim_and_shoot(target)
                self._visualize_frame(frame)
    
    def _execute_aim_and_shoot(self, target):
        """æ‰§è¡Œç„å‡†å’Œå°„å‡» - æ ¸å¿ƒé€»è¾‘"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ´»è·ƒçš„ç›®æ ‡ç±»åˆ«
        if hotkeys_watcher.clss is None:
            hotkeys_watcher.active_classes()
        
        if target.cls not in hotkeys_watcher.clss:
            return
        
        is_head_target = (target.cls == 7)
        target_velocity = math.sqrt(target.velocity_x**2 + target.velocity_y**2) if hasattr(target, 'velocity_x') else 0
        
        logger.info(f"ğŸ¯ Target acquired: {'HEAD' if is_head_target else 'BODY'}, aim_point=({target.aim_x:.1f}, {target.aim_y:.1f})")
        
        # ç®€åŒ–ç›´æ¥ç§»åŠ¨ï¼Œä¼ é€’å¤´éƒ¨æ ‡è¯†
        mouse.move_to_target(target.aim_x, target.aim_y, target_velocity, is_head_target)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å°„å‡»èŒƒå›´å†…
        if self.is_target_in_scope(target):
            logger.info("ğŸ”¥ Target in scope - ç®€å•ä¸‰è¿å‘")
            shooting.queue.put((True, mouse.get_shooting_key_state()))
        else:
            shooting.queue.put((False, mouse.get_shooting_key_state()))
    
    def find_best_target(self, frame):
        """æ‰¾åˆ°æœ€ä½³ç„å‡†ç›®æ ‡ - ä¼˜å…ˆå¤´éƒ¨ï¼Œé€‰æ‹©æœ€è¿‘çš„"""
        if isinstance(frame, sv.Detections):
            boxes_array, classes_tensor = self._convert_sv_to_tensor(frame)
        else:
            boxes_array = frame.boxes.xywh.to(self.arch)
            classes_tensor = frame.boxes.cls.to(self.arch)
        
        if not classes_tensor.numel():
            return None
        
        # å±å¹•ä¸­å¿ƒ
        center_x = capture.screen_x_center
        center_y = capture.screen_y_center
        center = torch.tensor([center_x, center_y], device=self.arch)
        
        # è®¡ç®—åˆ°å±å¹•ä¸­å¿ƒçš„è·ç¦»
        distances_sq = torch.sum((boxes_array[:, :2] - center) ** 2, dim=1)
        
        # å¤´éƒ¨ç›®æ ‡ä¼˜å…ˆçº§æ›´é«˜
        head_mask = classes_tensor == 7
        
        if head_mask.any():
            # é€‰æ‹©æœ€è¿‘çš„å¤´éƒ¨ç›®æ ‡
            head_distances = distances_sq[head_mask]
            nearest_head_idx = torch.argmin(head_distances)
            nearest_idx = torch.nonzero(head_mask)[nearest_head_idx].item()
            logger.info(f"ğŸ¯ Selected HEAD target at distance {math.sqrt(distances_sq[nearest_idx].item()):.1f}px")
        else:
            # æ²¡æœ‰å¤´éƒ¨ç›®æ ‡æ—¶é€‰æ‹©æœ€è¿‘çš„èº«ä½“ç›®æ ‡
            nearest_idx = torch.argmin(distances_sq)
            logger.info(f"ğŸ¯ Selected BODY target at distance {math.sqrt(distances_sq[nearest_idx].item()):.1f}px")
        
        # åˆ›å»ºç›®æ ‡å¯¹è±¡
        target_data = boxes_array[nearest_idx, :4].cpu().numpy()
        target_class = classes_tensor[nearest_idx].item()
        
        target = SimpleTarget(*target_data, target_class, time.time())
        
        # æ›´æ–°è·Ÿè¸ªå™¨å¹¶é¢„æµ‹ä½ç½®
        self.target_tracker.update_target(target)
        predicted_x, predicted_y = self.target_tracker.predict_position(target)
        
        # æ›´æ–°ç„å‡†ç‚¹ä¸ºé¢„æµ‹ä½ç½®
        if self.target_tracker.prediction_enabled:
            target.aim_x = predicted_x
            target.aim_y = predicted_y
            
            # ç®€åŒ–é¢„æµ‹æ›´æ–°ï¼šç›´æ¥è®¾ç½®ç„å‡†ç‚¹ä¸ºé¢„æµ‹ä½ç½®
            if target.cls == 7:  # å¤´éƒ¨
                target.aim_x = predicted_x
                target.aim_y = predicted_y + (target.h * 0.3)
            else:  # èº«ä½“
                target.aim_x = predicted_x
                target.aim_y = predicted_y - (target.h * 0.2)
        
        return target
    
    def is_target_in_scope(self, target):
        """æ£€æŸ¥ç›®æ ‡æ˜¯å¦åœ¨ç„å‡†é•œèŒƒå›´å†…"""
        center_x = capture.screen_x_center
        center_y = capture.screen_y_center
        
        # ä½¿ç”¨ç¼©å°çš„ç›®æ ‡æ¡†æ¥åˆ¤æ–­
        scope_reduction = cfg.bScope_multiplier if hasattr(cfg, 'bScope_multiplier') else 0.8
        reduced_w = target.w * scope_reduction / 2
        reduced_h = target.h * scope_reduction / 2
        
        # ç„å‡†é•œèŒƒå›´
        scope_left = target.aim_x - reduced_w
        scope_right = target.aim_x + reduced_w
        scope_top = target.aim_y - reduced_h
        scope_bottom = target.aim_y + reduced_h
        
        # æ£€æŸ¥å‡†æ˜Ÿæ˜¯å¦åœ¨èŒƒå›´å†…
        in_scope = (center_x > scope_left and center_x < scope_right and 
                   center_y > scope_top and center_y < scope_bottom)
        
        # å¼ºåˆ¶å°„å‡»æ¨¡å¼
        if hasattr(cfg, 'force_click') and cfg.force_click:
            in_scope = True
        
        # ç»˜åˆ¶ç„å‡†èŒƒå›´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if cfg.show_window and hasattr(cfg, 'show_bScope_box') and cfg.show_bScope_box:
            visuals.draw_bScope(scope_left, scope_right, scope_top, scope_bottom, in_scope)
        
        return in_scope
    
    def _convert_sv_to_tensor(self, frame):
        """è½¬æ¢supervisionæ£€æµ‹ç»“æœä¸ºtensoræ ¼å¼"""
        xyxy = frame.xyxy
        xywh = torch.tensor([
            (xyxy[:, 0] + xyxy[:, 2]) / 2,  # x center
            (xyxy[:, 1] + xyxy[:, 3]) / 2,  # y center
            xyxy[:, 2] - xyxy[:, 0],        # width
            xyxy[:, 3] - xyxy[:, 1]         # height
        ], dtype=torch.float32).to(self.arch).T
        
        classes_tensor = torch.from_numpy(np.array(frame.class_id, dtype=np.float32)).to(self.arch)
        return xywh, classes_tensor
    
    def _visualize_frame(self, frame):
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        if cfg.show_window or cfg.show_overlay:
            if cfg.show_boxes or cfg.overlay_show_boxes:
                visuals.draw_helpers(frame.boxes)
            
            if cfg.show_window and cfg.show_detection_speed:
                visuals.draw_speed(frame.speed['preprocess'], frame.speed['inference'], frame.speed['postprocess'])
        
        # å¤„ç†æ— æ£€æµ‹æƒ…å†µ
        if not frame.boxes:
            if cfg.auto_shoot or cfg.triggerbot:
                shooting.shoot(False, False)
        
        if cfg.show_window or cfg.show_overlay:
            if not frame.boxes:
                visuals.clear()
    
    def get_arch(self):
        """è·å–è®¡ç®—è®¾å¤‡æ¶æ„"""
        if cfg.AI_enable_AMD:
            return f'hip:{cfg.AI_device}'
        elif 'cpu' in cfg.AI_device:
            return 'cpu'
        else:
            return f'cuda:{cfg.AI_device}'

# åˆ›å»ºå…¨å±€ç®€åŒ–å¸§è§£æå™¨å®ä¾‹
simpleFrameParser = SimpleFrameParser()